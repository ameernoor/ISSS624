[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Geospatial Analytics (ISSS624)",
    "section": "",
    "text": "Exploring Geospatial Analytics Illustration\n\n\nHello there! I’m Muhamad Ameer Noor, and this is my space dedicated to the exciting world of geospatial analytics. Join me on this journey as I delve into the fascinating realm of spatial data analysis and its applications.\n\n\nOn this webpage, I’ll be sharing insights, discoveries, and projects related to geospatial analytics that I learned from ISSS624 - Applied Geospatial Analytics Course under [MITB Programme at Singapore Management University] (https://masters.smu.edu.sg/programme/master-of-it-in-business). Whether you’re a fellow enthusiast, a student, or just curious about the power of location-based data, you’re in the right place!\n\n\n\nI’ll document my experiences and challenges as I navigate through ISSS624 Geospatial Analytics. Expect a mix of tutorials and case studies that showcase the practical applications of geospatial analytics.\n\n\n\nCurious about how this webpage was built? Check out the Quarto websites documentation\nThanks for stopping by, and let’s explore the world through geospatial analytics!"
  },
  {
    "objectID": "index.html#what-to-expect",
    "href": "index.html#what-to-expect",
    "title": "Applied Geospatial Analytics (ISSS624)",
    "section": "",
    "text": "On this webpage, I’ll be sharing insights, discoveries, and projects related to geospatial analytics that I learned from ISSS624 - Applied Geospatial Analytics Course under [MITB Programme at Singapore Management University] (https://masters.smu.edu.sg/programme/master-of-it-in-business). Whether you’re a fellow enthusiast, a student, or just curious about the power of location-based data, you’re in the right place!"
  },
  {
    "objectID": "index.html#learning-journey",
    "href": "index.html#learning-journey",
    "title": "Applied Geospatial Analytics (ISSS624)",
    "section": "",
    "text": "I’ll document my experiences and challenges as I navigate through ISSS624 Geospatial Analytics. Expect a mix of tutorials and case studies that showcase the practical applications of geospatial analytics."
  },
  {
    "objectID": "index.html#dive-deeper",
    "href": "index.html#dive-deeper",
    "title": "Applied Geospatial Analytics (ISSS624)",
    "section": "",
    "text": "Curious about how this webpage was built? Check out the Quarto websites documentation\nThanks for stopping by, and let’s explore the world through geospatial analytics!"
  },
  {
    "objectID": "hands-on/hoe1.html",
    "href": "hands-on/hoe1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "Data Wrangling Illustration"
  },
  {
    "objectID": "hands-on/hoe1.html#overview",
    "href": "hands-on/hoe1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1 Overview",
    "text": "1 Overview\nThis hands-on exercise is about importing and wrangling geospatial data using appropriate R packages."
  },
  {
    "objectID": "hands-on/hoe1.html#getting-started",
    "href": "hands-on/hoe1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "2 Getting Started",
    "text": "2 Getting Started\nThe code chunk below install and load sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "hands-on/hoe1.html#importing-geospatial-data",
    "href": "hands-on/hoe1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "3 Importing Geospatial Data",
    "text": "3 Importing Geospatial Data\nThe data import process uses a tool called st_read. It is a function to read different types of maps, in the format/extension such as .shp, .dbf, .prj, and .shx. The function use the following parameters:\n\nLocation Instruction (dsn Parameter): This part is specifying where to find the map files. In our case, the maps are in a folder called “../data/geospatial.”\nLayer Instruction (layer Parameter): This part is specifying focus on a specific aspect of the maps. Think of the maps as a big book, and a layer is like a section that talks about a particular topic. In our example, we’re interested in a section named “MP14_SUBZONE_WEB_PL,” which contains information about areas called subzones.\n\n\nPolygon Data in Shapefile FormatPolygon Data in Shapefile FormGIS data in KML format\n\n\n\nmpsz &lt;- st_read(dsn = \"../data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameernoor\\ISSS624\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nShapefiles are a common geospatial vector data format used to represent geographic features such as points, lines, and polygons. In this case, MP14_SUBZONE_WEB_PL is a layer within the shapefile containing polygon features, which could represent, for example, subzones in a geographic region. The Master Plan 2014 Subzone Boundary (Web) data is a forward looking guiding plan for Singapore’s development in the medium term over the next 10 to 15 years Development Master Plan 2014. Subzones are divisions within a planning area which are usually centred around a focal point such as neighbourhood centre or activity node. There can be more than 10 subzones within a Planning Area. The data is sourced from Singapore Government\n\n\n\n\ncyclingpath &lt;- st_read(dsn = \"../data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\ameernoor\\ISSS624\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\nThis code imports polyline feature data from a shapefile. Polylines are sequences of connected straight lines and are commonly used to represent linear features such as roads, rivers, or cycling paths. In this case, the data are line representations of an intra-town path around Singapore designated for cyclists, excluding park connectors. The data is sourced from Land Transport Authority\n\n\n\n\npreschool &lt;- st_read(dsn = \"../data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\ameernoor\\ISSS624\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nThis code import GIS (Geographic Information System) in KML format. KML (Keyhole Markup Language) is an XML-based format often used for expressing geographic annotation and visualization within Internet-based, two-dimensional maps and three-dimensional Earth browsers. In this example, the code imports geospatial data representing the location of pre-schools (childcare centres and kindergartens) around Singapore from a KML file. The data is sourced from Singapore Government"
  },
  {
    "objectID": "hands-on/hoe1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "hands-on/hoe1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "4 Checking the Content of A Simple Feature Data Frame",
    "text": "4 Checking the Content of A Simple Feature Data Frame\nWhen working with a geospatial data frame like ‘mpsz’ (or any dataset in general), it’s essential to understand its structure and content. The following codes are for checking and understanding the data:\n\nExtracting Geometric Information with st_geometry.Overview of Data Structure with ‘glimpse’Previewing Data with ‘head’\n\n\nThe st_geometry function is used to extract the geometric information (shapes) from the mpsz (Master Plan Subzone Boundary 2014) feature data frame.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\nFrom the output of the code, it can be summarized that:\n\nThe dataset contains 323 features, each representing a geographic entity. The geometry type used is MULTIPOLYGON, indicating that these features consist of multiple connected polygons.\nThe dimension is XY, implying that the geometry is represented in a two-dimensional space with X and Y coordinates.\nThe bounding box provides the spatial extent of the dataset which includes xmin (minimum X-coordinate), ymin (minimum Y-coordinate), xmax (maximum X-coordinate), and ymax (maximum Y-coordinate)\nProjection Information: The data is projected in the SVY21 coordinate reference system (CRS). SVY21 is a coordinate system used in Singapore for accurate spatial representation.\nFirst 5 Geometries: The output displays the geometries for the first 5 features in the dataset, each represented as a MULTIPOLYGON.\n\n\n\n\nThe glimpse function is employed to obtain a quick overview of the structure and content of the ‘mpsz’ data frame, offering insights into its shape, variables and data types.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nFrom the output of the code, it can be summarized that the dataset contains 323 row and 16 columns, with various data type including integer (int), characters/string (chr), date, double-precision floating-point/64bit float (dbl), and multipolygon\n\n\n\nThe head function is utilized to display the initial 5 rows of the ‘mpsz’ data frame, providing a glimpse of its data values. The n=5 parameter specifies the number of rows to be shown (in this case, the first 5 rows).\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nThe output describes the data as a Simple feature collection with 5 features and 15 fields. Note that the features will change in accordance with the numer in the ‘n’ parameter changed. Field represents the number of columns in the dataset. Note that it only count 15 columns in the dataset as opposed to 16 columns in ‘glimpse’ function. It is because of the ‘geometry’ column is not counted as a ‘geometry’ column is not counted as a ‘simple feature’."
  },
  {
    "objectID": "hands-on/hoe1.html#visualizing-the-geospatial-data-on-chartplot",
    "href": "hands-on/hoe1.html#visualizing-the-geospatial-data-on-chartplot",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "5 Visualizing the Geospatial Data on Chart/Plot",
    "text": "5 Visualizing the Geospatial Data on Chart/Plot\nIn geospatial data science, by looking at the feature information is not enough. We are also interested to visualise the geospatial features. THe following visualization use plot function from sf library. Note that ‘plot()’ function is mean for plotting the geospatial object for quick look. For high cartographic quality plot, other R package such as tmap should be used.\n\nPlotting All FeaturesPlotting Only the Geometric ShapesPlotting Based on a Specific Attribute\n\n\nThe plot function is used to visualize all features in the ‘mpsz’ dataset. The max.plot parameter limits the display to a maximum of 15 features\n\nplot(mpsz, max.plot = 15)\n\n\n\n\n\n\nHere, the plot function is applied to display only the geometric shapes from the ‘mpsz’ dataset. The st_geometry function extracts the geometries, and the plot focuses solely on the spatial representation.\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\nThis code utilizes the plot function to visualize features from the ‘mpsz’ dataset based on the attribute “PLN_AREA_N.” The resulting plot highlights spatial distributions based on the specified attribute, providing insights into the geographic distribution of the selected feature.\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "hands-on/hoe1.html#working-with-projection",
    "href": "hands-on/hoe1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "6 Working with Projection",
    "text": "6 Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system. In this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n6.1 Assigning EPSG code to a simple feature data frame\nOne of the common issue that can happen during importing geospatial data into R is that the coordinate system of the source data was either missing (such as due to missing .proj for ESRI shapefile) or wrongly assigned during the importing process.\n\nChecking default EPSG CodeCorrecting EPSG CodeChecking Correction Result\n\n\nThe st_crs is a function to retrieve coordinate reference system from sf or sfc object. In this case, it is used to obtain the current EPSG code of the ‘mpsz’ dataset, providing information about its current coordinate reference system. The EPSG code (European Petroleum Survey Group) is a standardized identifier used to uniquely reference a coordinate reference system.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414. This code assigns the EPSG code 3414 to the ‘mpsz’ dataset, ensuring that it adheres to the SVY21 coordinate reference system (EPSG 3414) for accurate spatial representation.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\n\n\nThe following code is to re-run st_crs to verify that the correction was successful by displaying the updated EPSG code (EPSG 3414) of the ‘mpsz3414’ dataset.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n\n\n\n6.2 Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements. This following code utilizes st_transform to convert the projection of the preschool dataset from the WGS84 coordinate system to the SVY21 coordinate system (EPSG 3414). This transformation ensures compatibility with other spatial data in the SVY21 projection.\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)"
  },
  {
    "objectID": "hands-on/hoe1.html#importing-and-converting-an-aspatial-data",
    "href": "hands-on/hoe1.html#importing-and-converting-an-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "7 Importing and Converting an Aspatial Data",
    "text": "7 Importing and Converting an Aspatial Data\nIn practice, it is not unusual that we will come across data such as listing of Inside Airbnb. We call this kind of data aspatial data. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points. In this section, you will learn how to import an aspatial data into R environment and save it as a tibble data frame. Next, you will convert it into a simple feature data frame.\n\nImporting the aspatial dataCreating a simple feature data frame from an aspatial data frame\n\n\nSince listings data set is in csv file format, we will use read_csv() of readr package to import listing.csv as shown the code chunk below. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"../data/aspatial/listings.csv\")\n\nDisplaying the Aspatial Data This code displays the content of the ‘listings’ data frame, providing a preview of its structure and values.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\nThe output reveals that listing tibble data frame consists of 4252 rows and 16 columns. Two useful fields we are going to use in the next phase are latitude and longitude. Note that they are in decimal degree format. As a best guess, we will assume that the data is in wgs84 Geographic Coordinate System.\n\n\n\nThis code converts the listings data frame into a simple feature data frame named listings_sf. It assigns coordinates and transforms the CRS to SVY21 (EPSG 3414) for accurate spatial representation\n\nlistings_sf &lt;- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %&gt;% st_transform(crs = 3414)\n\n\nThings to learn from the arguments above: - coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates. - crs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io. - %&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nexamine the content using glimpse function\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "hands-on/hoe1.html#geoprocessing-with-sf-package",
    "href": "hands-on/hoe1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "8 Geoprocessing with sf package",
    "text": "8 Geoprocessing with sf package\nBesides providing functions to handling (i.e. importing, exporting, assigning projection, transforming projection etc) geospatial data, sf package also offers a wide range of geoprocessing (also known as GIS analysis) functions. In this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\nBufferingPoint-in-polygon count\n\n\nThe scenario: The authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to\nThe solution: determine the extend of the land need to be acquired and their total area. This code calculates 5-meter buffers around cycling paths and stores the result in the ‘buffer_cycling’ dataset.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist=5, nQuadSegs = 30)\n\ncalculate the area of buffers The code adds a new column, ‘AREA,’ to the ‘buffer_cycling’ dataset, containing the calculated area of each buffer.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nderive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nThe scenario A pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\n** The solution: The code counts the number of pre-schools within each Planning Subzone using the st_intersects() function and updates the ‘PreSch Count’ column in the ‘mpsz3414’ dataset. Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$'PreSch Count'&lt;- lengths(st_intersects(mpsz3414, preschool3414)) \n\nchecking the summary statistics\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nchecking the subzone with most number of pre-school To list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\ncalculating the density of pre-school by planning subzone This code calculates the area of each Planning Subzone and adds a new column, ‘Area,’ to the ‘mpsz3414’ dataset.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\ncompute pre-schoold density The code computes the density of pre-schools per square kilometer for each Planning Subzone, providing a measure of the concentration of educational facilities in different areas.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "hands-on/hoe1.html#exploratory-data-analysis-eda",
    "href": "hands-on/hoe1.html#exploratory-data-analysis-eda",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "9 Exploratory Data Analysis (EDA)",
    "text": "9 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\n\nPlotting histogram for PreSch DensityPlot better histogram using GG PlotPlot a scatterplot using GGPlot\n\n\nThe histogram visualizes the distribution of pre-school density across different Planning Subzones, providing insights into the variation and concentration of pre-schools in Singapore.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\nThis GG Plot-generated histogram offers a more detailed view of pre-school density, allowing for a nuanced exploration of the distribution in Planning Subzones. The chart provides additional context on the prevalence of single pre-school areas versus those with higher concentrations.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\nThis scatterplot employs GG Plot to illustrate the relationship between pre-school density and count in different Planning Subzones. It helps identify patterns, clusters, or outliers, facilitating a comprehensive understanding of the distribution and concentration of pre-schools. The chart is limited to a specific range for clarity in visualization.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "data/geospatial/MPSZ-2019.html",
    "href": "data/geospatial/MPSZ-2019.html",
    "title": "ISSS624 - Applied Geospatial Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html",
    "href": "hands-on/hoe1-choropleth.html",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "",
    "text": "Painting Choropleth Map Illustration"
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html#overview",
    "href": "hands-on/hoe1-choropleth.html#overview",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "1 Overview",
    "text": "1 Overview\nIn this hands-on exercise, we will continue on Exploratory Data Analysis, specifically using Choropleth Mapping\nChoropleth mapping is a way to represent regions, like countries or states, by using patterns or colors to show different values. For instance, a social scientist might use a choropleth map to display where the older population is located in Singapore based on the Master Plan 2014 Subzone Boundary.\nIn this chapter, you’ll discover how to create accurate and meaningful choropleth maps using an R package called tmap."
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html#import-the-libraries",
    "href": "hands-on/hoe1-choropleth.html#import-the-libraries",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "2 Import The Libraries",
    "text": "2 Import The Libraries\nThe code chunk below install and load sf, tidyverse and tmap packages into R environment.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html#importing-the-data",
    "href": "hands-on/hoe1-choropleth.html#importing-the-data",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "3 Importing The Data",
    "text": "3 Importing The Data\nWe’ll use two sets of information to make the choropleth map:\n\nMaster Plan 2014 Subzone Boundary (Web): This is a map file that shows the shape of different areas in Singapore, specifically at the planning subzone level. The data can be downloaded from Singapore Government\nSingapore Residents Data (June 2011-2020): This is a list of information about people living in Singapore, like how many people are in different age groups, their gender, and the type of homes they live in. This data is in a CSV file (respopagesextod2011to2020.csv). The data can be downloaded from the Department of Statistics, Singapore. Even though it doesn’t have actual location coordinates, it has fields called PA and SZ that can help match it to the shapes in the MP14_SUBZONE_WEB_PL file.\n\n\nGeospatial Data (Subzone Boundary)Attribute Data\n\n\nThe code below does the following 1. uses the st_read() function from the sf package to bring in the MP14_SUBZONE_WEB_PL shapefile into R, and import it as a simple feature data frame named mpsz. 2. display the data frame by calling mpsz\n\nmpsz &lt;- st_read(dsn = \"../data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\ameernoor\\ISSS624\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\n\nNote that only the first ten records are displayed. By default, R shows a summary of only the first few rows to minimize resource usage and avoid overwhelming the user. To see more rows, you can use functions like head() and specify the n parameter, e.g. head(mpsz, n = 20) to display the first 20 rows.\n\n\n\nNext, we’re going to bring in the respopagsex2011to2020.csv file into RStudio and store it in a data table named popdata. We’ll do this using the read_csv() function from the readr package, as you can see in the code snippet below.\n\npopdata &lt;- read_csv(\"../data/aspatial/respopagesextod2011to2020.csv.gz\")"
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html#data-preparation",
    "href": "hands-on/hoe1-choropleth.html#data-preparation",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "4 Data Preparation",
    "text": "4 Data Preparation\nBefore making a special map, you need to create a table with data for the year 2020. This table should have information about different areas (PA, SZ) and various age groups like YOUNG (0-4 to 20-24), ECONOMY ACTIVE (25-29 to 60-64), AGED (65 and above), TOTAL (all age groups), and DEPENDENCY (the ratio of young and aged people to the economy-active group).\n\nData WranglingJoining the attribute data and geospatial data\n\n\nWe’ll be using some functions to shape our data the way we want: - pivot_wider() from tidyr package - mutate(), filter(), group_by(), and select() from dplyr package\nThe code will do the following steps in order: - Filter the data: It only keeps the rows where the Time column is 2020. - Group the data: It groups the data by PA (Planning Area), SZ (Subzone), and AG (Age Group). - Summarize the data: It calculates the sum of the Pop column for each group. - Reshape the data: It spreads the data wide, turning the Age Group values into separate columns. - Create new columns: It calculates the YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY values based on the grouped and summarized data. - Select the columns: It picks the specific columns to be kept in the final data table.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\nglimpse(popdata2020)\n\nRows: 332\nColumns: 7\n$ PA               &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio…\n$ SZ               &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Cheng San\", \"Chong Boon\", …\n$ YOUNG            &lt;dbl&gt; 1440, 6640, 6150, 5540, 2100, 3960, 2220, 4690, 0, 12…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2610, 15460, 13950, 12090, 3410, 8420, 4200, 11450, 0…\n$ AGED             &lt;dbl&gt; 760, 6050, 6470, 5120, 1310, 3610, 1530, 5100, 0, 750…\n$ TOTAL            &lt;dbl&gt; 4810, 28150, 26570, 22750, 6820, 15990, 7950, 21240, …\n$ DEPENDENCY       &lt;dbl&gt; 0.8429119, 0.8208279, 0.9046595, 0.8817204, 1.0000000…\n\n\n\n\nBefore we can combine our geographic and population data, we need to make sure the values in the PA and SZ fields are all in uppercase. This is because these values have a mix of upper- and lowercase, while SUBZONE_N and PLN_AREA_N are all in uppercase.\nthe following code will change the values in the PA and SZ columns to uppercase. After that, it will filters out rows where the ECONOMY ACTIVE column is greater than 0.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\nglimpse(popdata2020)\n\nRows: 234\nColumns: 7\n$ PA               &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO…\n$ SZ               &lt;chr&gt; \"ANG MO KIO TOWN CENTRE\", \"CHENG SAN\", \"CHONG BOON\", …\n$ YOUNG            &lt;dbl&gt; 1440, 6640, 6150, 5540, 2100, 3960, 2220, 4690, 1220,…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2610, 15460, 13950, 12090, 3410, 8420, 4200, 11450, 2…\n$ AGED             &lt;dbl&gt; 760, 6050, 6470, 5120, 1310, 3610, 1530, 5100, 750, 4…\n$ TOTAL            &lt;dbl&gt; 4810, 28150, 26570, 22750, 6820, 15990, 7950, 21240, …\n$ DEPENDENCY       &lt;dbl&gt; 0.8429119, 0.8208279, 0.9046595, 0.8817204, 1.0000000…\n\n\nNow, we’re using left_join() from the dplyr package to connect our geographical data and the population attribute table. This connection is made using planning subzone names, specifically SUBZONE_N in the geographical data and SZ in the attribute table, as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\nglimpse(mpsz_pop2020)\n\nRows: 323\nColumns: 22\n$ OBJECTID         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…\n$ SUBZONE_NO       &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, …\n$ SUBZONE_N        &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERS…\n$ SUBZONE_C        &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BM…\n$ CA_IND           &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\"…\n$ PLN_AREA_N       &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT M…\n$ PLN_AREA_C       &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\",…\n$ REGION_N         &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\",…\n$ REGION_C         &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC          &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13…\n$ FMEL_UPD_D       &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014…\n$ X_ADDR           &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 253…\n$ Y_ADDR           &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 299…\n$ SHAPE_Leng       &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 442…\n$ SHAPE_Area       &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.4…\n$ PA               &lt;chr&gt; NA, \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\", \"BUKI…\n$ YOUNG            &lt;dbl&gt; NA, 1200, 0, 3150, 2900, 3340, 3130, 0, 1290, 50, NA,…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; NA, 2860, 40, 6900, 6020, 6800, 7700, 50, 2600, 140, …\n$ AGED             &lt;dbl&gt; NA, 2120, 10, 3320, 1740, 3420, 3610, 10, 610, 60, NA…\n$ TOTAL            &lt;dbl&gt; NA, 6180, 50, 13370, 10660, 13560, 14440, 60, 4500, 2…\n$ DEPENDENCY       &lt;dbl&gt; NA, 1.1608392, 0.2500000, 0.9376812, 0.7707641, 0.994…\n$ geometry         &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOL…\n\n\n\nleft_join() is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\n\nLastly, the write_rds() function is used to save our combined data (stored in the mpsz_pop2020 data frame) into an RDS file.\n\nwrite_rds(mpsz_pop2020, \"../data/rds/mpszpop2020.rds\")\n\n\nAn RDS file is a binary file format used in R to store single R objects. It stands for R Data Store. This file format is efficient for saving and loading R objects because it preserves the object’s structure, including its data type, attributes, and metadata. Unlike other formats like CSV or Excel, RDS files are tailored for R-specific objects and are typically smaller in size. When you save an object as an RDS file, you can later load it back into R using the read_rds() function to retrieve the exact R object with all its properties intact. It’s a handy way to store and share R data without losing any of the specific characteristics of the objects."
  },
  {
    "objectID": "hands-on/hoe1-choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands-on/hoe1-choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1: Choropleth Mapping",
    "section": "5 Choropleth Mapping Geospatial Data using tmap",
    "text": "5 Choropleth Mapping Geospatial Data using tmap\nThere are two ways to make a thematic map using tmap: - Quick Approach: Use qtm() to swiftly draw a choropleth map. - Customizable Approach: Create a highly customizable thematic map by using tmap elements.\n\n5.1 Plotting choropleth map using qtm\nThe fastest way to draw a choropleth map using tmap is with qtm(). It’s straightforward and produces a solid default visualization in many cases.\nThe following code snippet will generate a standard choropleth map.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n5.2 Creating a choropleth map by using tmap’s elements\nDespite its quick and easy way of making a choropleth map, the limitation of using qtm() is that it makes it challenging to control the appearance of individual map layers. For a high-quality cartographic choropleth map, it’s better to use tmap’s drawing elements.\nThe next code will do the following steps: - tm_shape(): This sets the spatial object (mpsz_pop2020) to be used in the map.\n\ntm_fill(): It fills the polygons with colors based on the “DEPENDENCY” column, using the quantile method and a blue color palette.\ntm_layout(): Defines the layout elements, including the main title, legend settings, frame, and other stylistic elements.\ntm_borders(), tm_compass(), tm_scale_bar(), tm_grid(): These add map embellishments such as borders, compass, scale bar, and grid.\ntm_credits(): Adds a text credit at the bottom left of the map, mentioning the data sources.\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\neach of the tmap functions that are used to create the plot can be seen in the following panel.\n\nbase maptm_polygonstm_filltm_border\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nwithout setting the border, the planning subzones will not have any boundary if the dependency value is the same\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\nParameters of tm_border(): - alpha = transparency. the default value is 1 (not transparent) - col = border colour, - lwd = border line width. The default is 1, and - lty = border line type. The default is “solid”.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\n\n5.3 Data Classification methods of tmap\nChoropleth maps usually use different ways to group data, and the goal is to organize a bunch of observations into specific ranges or groups.\ntmap offers ten methods to classify data, including fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo pick a data classification method, you use the style argument in tm_fill() or tm_polygons().\n\n5.3.1 Plotting choropleth maps with built-in classification methods\nThe following panel will compare various choropleth maps with built-in classification methods and constant n = 5\n\njenksequalsdprettyquantilehclustfisherfisher\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing equal range data classification, the map is not too informative as the data is skewed\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nVarious method of classification can give highly different result. One of the main contributor is due to skewness and presence of outliers in the data. Classification method which is insensitive to it will give monotonous map, where only a few region have different color, and vice versa. As an analyst, domain knowledge is required to decide which classification method is the most appropriate (i.e. whether small differences between the Dependency data matters). Ultimately, the method chosen should be able to support the best decision making.\n\nThe following panel will compare various choropleth maps with different number of classes\n\njenks 2 classesequal 6 classesequal 10 classesequal 20 classes\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nsimilar to classification method, number of classes could matter in showing differences between area. with n set as 2, even jenks method become monotonous, revealing the outlier area. on the other hand, with n set as high as 20, even the equal method start to show differences between region, albeit subtle (due to high degree of skewness/presence of extreme outliers)\n\n\n\n5.3.2 Plotting choropleth map with custom break\nthe automated break calculation in previous method can be overriden by explicitly set the break arguments.\nbefore starting, the following code will show descriptive statistics to be used for break reference.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nwith reference to the summary statistics result, the break point is set at 0.60, 0.70, 0.80, and 0.90. The arguments also requires to include minimum and maximum value.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n5.4 Colour Scheme\nThe color scheme in tmap can be customized using user-defined or predefined color ramps from the RColorBrewer package.\nTo use a ColorBrewer palette, you assign the desired color to the palette argument of tm_fill(). If you want to change the color, you can do so by specifying the palette in the code.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe above choropleth map is shaded in green. To reverse the color shade use “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe colour scheme also changed with the new setting.\n\n\n5.5 Map Layouts\nMap layouts refer to combining all map elements into a cohesive map, including objects, title, scale bar, compass, margins, aspect ratios, color settings, and data classification methods. In tmap, various legend options are available to change the placement, format, and appearance of the legend. You can use tm_fill() along with tm_layout() to customize the legend based on your preferences. To change the style of layout, use tmap_style(). The following panel show how the various options are used.\n\nAdding legendClassic Map StyleCartographic Furniture Map Style\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\nreset the tmap setting to default style.\n\ntmap_style(\"white\")\n\n\n\n5.6 Drawing Small Multiple Choropleth Maps\nSmall multiple choropleth maps, or facet maps, display many maps side-by-side or stacked vertically. tmap allows you to create small multiples in different ways, such as assigning multiple values to aesthetic arguments or using tm_facets().\nYou can also create small multiples by defining a group-by variable in tm_facets() or by creating multiple stand-alone maps with tmap_arrange(). Each method offers flexibility in visualizing spatial relationships.\n\nassigning multiple values to one aesthetic argumentsassigning multiple values to more than one aesthetic argumentsdefining a group-by variable in tm_facetscreating multiple stand-alone maps with tmap_arrange\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"), style = c(\"equal\", \"quantile\"), palette = list(\"Blues\",\"Greens\")) + tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + tm_polygons(\"YOUNG\", style = \"quantile\", palette = \"Blues\")\nagedmap &lt;- tm_shape(mpsz_pop2020) + tm_polygons(\"AGED\", style = \"quantile\", palette = \"Blues\")\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n5.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can use selection functions to map spatial objects meeting specific criteria. This allows you to focus on specific regions or areas in the map based on your selection criterion. The following code choose Central Region as example\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "in-class/ice1.html",
    "href": "in-class/ice1.html",
    "title": "In-class Exercise 1: Preparing the Data Flow",
    "section": "",
    "text": "Preparing Data Flow Illustration"
  },
  {
    "objectID": "in-class/ice1.html#getting-started",
    "href": "in-class/ice1.html#getting-started",
    "title": "In-class Exercise 1: Preparing the Data Flow",
    "section": "1 Getting Started",
    "text": "1 Getting Started\nThe code chunk below load the following packages: - tmap: for thematic mapping - sf : for geospatial data handling - tidyverse for non-spatial data handling.\n\npacman::p_load(tmap, sf, tidyverse)\n# load the libraries, the pacman itself will only be loaded temporarily"
  },
  {
    "objectID": "in-class/ice1.html#preparing-the-data-flow",
    "href": "in-class/ice1.html#preparing-the-data-flow",
    "title": "In-class Exercise 1: Preparing the Data Flow",
    "section": "2 Preparing the Data Flow",
    "text": "2 Preparing the Data Flow\n\n2.1 Importing the Aspatial data\nImport the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\n#|eval: false\nodbus &lt;- read_csv(\"../data/aspatial/origin_destination_bus_202308.csv.gz\")\nhead(odbus)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;              \n1 2023-08    WEEKDAY               16 BUS     04168          10051              \n2 2023-08    WEEKENDS/…            16 BUS     04168          10051              \n3 2023-08    WEEKENDS/…            14 BUS     80119          90079              \n4 2023-08    WEEKDAY               14 BUS     80119          90079              \n5 2023-08    WEEKENDS/…            17 BUS     44069          17229              \n6 2023-08    WEEKDAY               17 BUS     44069          17229              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\n\nChange Character Data Type to Numerical Factor\nodbus08 is a tibble dataframe. However, ORIGIN_PT_CODE and DESTINATION_PT_CODE are in character format. These are transformed into factors (categorical data type) for further analysis.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\nExtracting the data for analysis\nextract commuting flows by extracting Origin bus stop codes and number of trips for weekdays between 7 and 9 o’clock, into a new dataframe:\n\norigtrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\nglimpse(origtrip_7_9)\n# the %&gt;% sign is for stepping the process in order \n\n\n\n\n2.2 Importing the geospatial data\nTwo geospatial data will be used in this exercise both data contain coordinate in geometry column:\n\n#} eval: false\nbusstop &lt;- st_read(dsn = \"../data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414) # the st_transform is for projection\n\nReading layer `BusStop' from data source `C:\\ameernoor\\ISSS624\\data\\geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\nmpsz &lt;- st_read(dsn = \"../data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\nglimpse(mpsz)"
  }
]