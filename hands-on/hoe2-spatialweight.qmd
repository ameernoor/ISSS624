---
title: "Hands-on Exercise 2: Spatial Weights and Application"
editor: visual
format: 
  html:
    code-fold: true
    code-summary: "code chunk"
    number-sections: true
    number-depth: 3
execute:
  echo: true # all code chunk will appear
  eval: true # all code chunk will running live (be evaluated)
  warning: false # don't display warning
---

![Weighing Space Illustration](../images/spatialweighting.png)

## Overview

::: {.notebox .lightbulb data-latex="lightbulb"}
**Spatial analysis** is a method used to understand the significance of spatial relationships between different objects. It's like **figuring out how different pieces on a chessboard influence each other's moves**. **Spatial weights** are concepts that help us measure and analyze how different locations or regions are **related to each other based on their proximity, similarity, or interaction**. Spatial weights are **numerical values** that represent the strength or **intensity of the connection** between two spatial units, such as points, polygons, or pixels. Applications of spatial weights include detecting patterns, clusters, outliers, hot spots, or cold spots in spatial data, and testing hypotheses about spatial processes or phenomena.
*summarized from: [Getis, 2010](https://learnr.web.unc.edu/wp-content/uploads/sites/7634/2020/03/Getis_2010_HandbookAppSpatAnalysis-1.pdf)*
:::

The data used for practice in this exercise includes a map outlining the **boundaries of Hunan county**, presented as a geospatial dataset in ESRI shapefile format, and a CSV file named "Hunan_2012.csv," which includes specific **local development indicators** for Hunan in the year 2012.

This exercise will help to get familiar with importing geospatial data using functions from the [sf](https://r-spatial.github.io/sf/) package, reading CSV files with functions from the [readr](https://www.rdocumentation.org/packages/readr/versions/2.1.4) package, conducting relational joins through functions from the [dplyr](https://www.rdocumentation.org/packages/dplyr/versions/1.0.10) package, computing spatial weights calculating spatially lagged variables using functions from the [spdep](https://cran.r-project.org/web/packages/spdep/index.html) package.

## Preparing the Library and Data

The following code chunk will import the required library:

```{r}
#| code-fold: false
pacman::p_load(sf, spdep, tmap, tidyverse, knitr)
```

The following panel will show how the data is imported and joined

::: panel-tabset
### Import Shapefile

the following code use `st_read()` from **sf** package to import Hunan shapefile into **simple features** Object

```{r}
#| code-fold: false
hunan <- st_read(dsn = "../data/geospatial", layer = "Hunan")
glimpse(hunan)
```

### Import CSV

the following code use `read_csv()` from **readr** package to import

```{r}
#| code-fold: false
hunan2012 <- read_csv("../data/aspatial/Hunan_2012.csv")
glimpse(hunan2012)
```

### Import CSV

The following code use `left_join()` from **dplyr** package to merge the aspatial data to the geospatial data

```{r}
#| code-fold: false
hunan <- left_join(hunan,hunan2012)%>%
  select(1:4, 7, 15)
head(hunan, n = 10)
```
:::

## Visualizing Regional Development Indicator

this section will explore distribution of *Gross Domestic Product Per Capita* (GDPPC) 2012 in Hunan by creating  *base map* and build *choropleth* map. `qtm()` from **tmap** package is used to build the map.

```{r}
# Creating The Basemap
basemap <- tm_shape(hunan) +
  tm_polygons() +
  tm_text("NAME_3", size = 0.5) +
  tm_layout(main.title = "Basemap", main.title.position = "left")  # Add title

# Creating The Choropleth Map
gdppc <- qtm(hunan, "GDPPC") +
  tm_layout(main.title = "Choropleth Map", main.title.position = "left",
            legend.outside = TRUE, legend.outside.position = 'right')  # adjust the legend

# show the map
tmap_arrange(basemap, gdppc, asp=1, ncol=2, widths = c(0.4,0.6))
```

## Computing Contiguity Spatial Weights

::: {.notebox .lightbulb data-latex="lightbulb"}
Contiguity Spatial Weights are used in spatial data analysis to understand how close or connected different geographic areas are to each other. Simply put, if two areas, like counties or neighborhoods, share a border, they're considered "contiguous" or neighbors. This concept is important for understanding patterns like how a phenomenon in one area might affect neighboring areas.
Two main criteria are used to define contiguity: 'rook' and 'queen'. Rook contiguity means areas are neighbors if they share a common edge. Queen contiguity is a bit broader, including areas that share either a common edge or a corner. This is akin to the movements of rook and queen pieces in chess
*Summarized from: [Anselin](https://lanselin.github.io/introbook_vol1/CHcontiguityweights.html)*
:::

![Queen vs Rook Contiguity](../images/choropleth.png)
*Source: [Research Gate](https://www.researchgate.net/figure/Figure-S1-Spatial-contiguity-weights-Rooks-and-Queens-A-Rooks-Weight-B-Queenss_fig1_309672985)*


This section explore `poly2nb()` from **spdep** package to compute contiguity weight matrices. The function builds a neighbours list based on regions with contiguous boundaries. Using “queen” parameter that takes TRUE or FALSE as options, if it is set to TRUE, the function will return a list of first order neighbours using the Queen criteria.

::: panel-tabset
### Queen
```{r}
#| code-fold: false
wm_q <- poly2nb(hunan, queen=TRUE)
summary(wm_q)
```
The output summarizes the spatial relationships in Hunan using Queen's contiguity method. There are 88 regions, and the analysis reveals a total of 448 connections among them. The percentage of nonzero weights, indicating connected regions, is approximately 5.79%. On average, each region has around 5.09 links with other regions. The distribution of links shows that most regions have 4 or 5 connections, with the least connected regions being 30 and 65, each having only 1 link. The most connected region is labeled as 85, with 11 links.


to list all neighboring polygons of a unit, use `wm_q` as shown in the following code, where 1 represent the polygon Unit ID being shown, and the output shows the 5 negiboring polygon Unit ID
```{r}
wm_q[[1]]
```
to retrieve the name of the county, use the following code
```{r}
hunan$County[1]
```
to retrieve county names of more than one polygons, use the following example that display the neigbor of Anxiang
```{r}
hunan$NAME_3[c(2,3,4,57,85)]
```
additionally the GDDPC data of multiple countries can also be displayed using the following code
```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```
to display the complete *weight matrix* which represent the neigbors of each region, use the following code
```{r}
str(wm_q)
```
### Rook
Similar to the example of Queen method, Rook method can be executed by changing queen parameter to False
```{r}
wm_r <- poly2nb(hunan, queen=FALSE)
summary(wm_r)
```
As expected from the ***stricter condition of Rook compared to Queen, the regions will have less neighbor on average***

### Visualising Contiguity Weights
To create a connectivity graph, we first need to represent polygons as points. In our case, we're working with polygons, so we'll use polygon centroids as points for our graph. The common approach is to calculate these centroids using the sf package. To achieve this, we employ the `st_centroid` function on the geometry column of our spatial object (in this case, hunan). Since we require the coordinates in a separate data frame, we utilize a mapping function. This function applies `st_centroid` to each element of the geometry column and returns a vector of the same length. We specifically use the map_dbl variation from the purrr package. For latitude and longitude values, we extract them using double bracket notation, [[1]] for longitude and [[2]] for latitude. Finally, we combine these coordinates into a single object using `cbind()`, and we verify the formatting by checking the first few observations using `head()`.
```{r}
longitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])

latitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])

coords <- cbind(longitude, latitude)

head(coords)
```
Next, the following code will be used to display and compare Queen and Rook contiguity neighbours maps
```{r}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="Queen Contiguity")
plot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= "red")
plot(hunan$geometry, border="lightgrey", main="Rook Contiguity")
plot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```
:::

## Computing Distance Based Neighbours
In this part, we will explore how to figure out which areas are close to each other using distances, by utilizing `dnearneigh()` function from the **spdep** package.

This function looks at points on a map and finds their neighbors based on how far apart they are. Range of distances can be set using `bounds` argument, with a lower limit `d1=` and an upper limit `d2=`. If the locations are given in regular coordinates (like x and y on a typical map) and *latitude and longitude* argument set to true (`longlat=TRUE`), the function measures distances in kilometers. It does this as if by figuring out how far it is on the Earth's surface, using something called the WGS84 reference ellipsoid.

::: {.notebox .lightbulb data-latex="lightbulb"}
The WGS84 reference ellipsoid is a mathematical model that approximates the shape of the Earth. It's not a perfect sphere but more like a slightly squashed ball, wider at the equator than at the poles. When measuring distances using this model, it considers the Earth's curvature. This method provides a more accurate way to measure real distances on the Earth's surface, especially over long distances where the Earth's curvature becomes significant. ***It's like tracing a line along the surface of an orange, rather than cutting straight through it.***
:::

The following part will explore how to find the right distance cut-off, fixed distance calculation, and adaptive distance calculation.

### Determine the cut-off distance

To find the right distance for the analysis, execute the following steps:

- Use [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) to get a list of indices representing the k nearest neighbors for each point.
- Convert this list into a neighbor list with [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).
- Find the lengths of these neighbor relationships with [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html).
Remove any complex structure with [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
#coords <- coordinates(hunan)
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary shows that the maximum distance to the first nearest neighbor is 61.79 km. Use it as threshold to ensure each unit has at least one neighbor.

### Computing fixed distance weight matrix
Based on the previous knowledge, create the distance weight matrix using the specified distance range (0 to 62 km).

```{r}
wm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)
wm_d62
```

::: {.notebox .lightbulb data-latex="lightbulb"}
The "Average number of links: 3.681818" means that, on average, each location is linked to approximately 3.68 other locations within the specified distance range.
:::

We can inspect the structure of the weight matrix using `str()` or combining [*table()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/table) and [*card()*](https://r-spatial.github.io/spdep/reference/card.html) of `spdep`.

```{r}
str(wm_d62)
```
the output shows for who are the neighbors of each county (shown in unit ID list per row)


```{r}
table(hunan$County, card(wm_d62))
n_comp <- n.comp.nb(wm_d62)
table(n_comp$comp.id)
```
the table shows, for each county, how many neighbors it has.
 
#### Overlapping Visualization
The red lines represent 1st nearest neighbors, while the black lines are links within the 62 km cut-off distance.
```{r fig.width=8, fig.height=6}
plot(hunan$geometry, border="lightgrey")
plot(wm_d62, coords, add=TRUE)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

#### Side by Side Visualization
```{r fig.width=12, fig.height=8}
par(mfrow=c(1,2))
plot(hunan$geometry, border="lightgrey", main="1st nearest neighbours")
plot(k1, coords, add=TRUE, col="red", length=0.08)
plot(hunan$geometry, border="lightgrey", main="Distance link")
plot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)
```

### Computing adaptive distance weight matrix

Using fixed distance, densely settled urban areas tend to have more neigbours compared to rural. Having many neighbours smoothes the neighbour relationship across more neighbours.
Number of neighbors can be adapted by accepting asymmetric neighbours or imposing symmetry.

The following code chunk impose 6 neighbors in the argument, hence the average number of links is 6 as well.

```{r}
knn6 <- knn2nb(knearneigh(coords, k=6))
knn6
```
Visualize the weight matrix.

```{r fig.width=8, fig.height=6}
plot(hunan$geometry, border="lightgrey")
plot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = "red")
```


## Weights based on IDW

Another method to derive spatial weight matrix is based on Inversed Distance method (IDW).

Compute distance of areas using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**.

```{r}
dist <- nbdists(wm_q, coords, longlat = TRUE)
ids <- lapply(dist, function(x) 1/(x))
ids
```

Assign equal weights (style="W") to neighboring polygons. It's calculated by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values.

::: {.notebox .lightbulb data-latex="lightbulb"}
One downside of using this approach is that regions at the edges of the study area might rely on fewer neighboring regions. This could lead to either overestimating or underestimating the real spatial connections in the data.

For a stronger and more reliable choice, you can use "style=B."
:::

```{r}
rswm_q <- nb2listw(wm_q, style="W", zero.policy = TRUE)
rswm_q
```

::: {.notebox .lightbulb data-latex="lightbulb"}
Be careful when setting zero.policy=TRUE because it lets you have lists of regions that are not neighbors. This can be risky because you might not notice if some neighbors are missing in your data. On the other hand, using zero.policy=FALSE would result in an error if there are missing neighbors.
:::


Check the weight of the first polygon's eight neighbors with the following code chunk.

```{r}
rswm_q$weights[10]
```
Each neighbor gets a share of 0.125 from the total weight. This implies that when R calculates the average income of neighboring areas, it multiplies each neighbor's income by 0.2 before adding them up.

We can apply a similar approach to create a distance weight matrix that is standardized by rows.
```{r}
rswm_ids <- nb2listw(wm_q, glist=ids, style="B", zero.policy=TRUE)
rswm_ids
```

```{r}
rswm_ids$weights[1]
```

```{r}
summary(unlist(rswm_ids$weights))
```

## Application of Spatial Weight Matrix

This part will explore how to create four types of spatial lagged variables as shown in the panel.

::: panel-tabset
### row-standardized weights
The following code computes the average neighbor GDPPC. These values are called ***spatially lagged values***.
```{r}
GDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)
GDPPC.lag
```

Recalling the GDPPC values obtained earlier for these five counties

```{r}
nb1 <- wm_q[[1]]
nb1 <- hunan$GDPPC[nb1]
nb1
```
::: {.notebox .lightbulb data-latex="lightbulb"}
Spatial Lag with Row-Standardized Weights method measures how much an observation at one location is influenced by observations at neighboring locations. The spatial lag is calculated as a weighted average, where the weights are standardized so that they add up to one for each location. This means that each location's value is influenced equally by its neighbors, creating a balanced representation of neighboring influence.
*summarized from: [Anselin](https://geodacenter.github.io/workbook/4d_weights_applications/lab4d.html)*
:::

We can add the spatially lagged GDPPC values to the *hunan* sf data frame using the following code:

```{r}
lag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))
lag.res <- as.data.frame(lag.list)
colnames(lag.res) <- c("NAME_3", "lag GDPPC")
hunan <- left_join(hunan,lag.res)
```

The table below shows the average neighboring income values for each region.

```{r}
head(hunan)
```

Next, plot both GDPPC and spatially lagged GDPPC for comparison.

```{r fig.width=12, fig.height=8}
gdppc <- qtm(hunan, "GDPPC")
lag_gdppc <- qtm(hunan, "lag GDPPC")
tmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)
```
::: {.notebox .lightbulb data-latex="lightbulb"}
using row-standardized weights, the distribution of lagged GDPPC on the right shows how neighboring countries becomes more similar.
note that some region which was originally much richer than it's neighbors, becomes poorer than its neighbors while it's neighbor becomes richer. **this indicates caution when using the row-standardized weights**
:::

### Spatial lag as a sum of neighboring values

We can calculate spatial lag as a sum of neighboring values using binary weights. This involves going back to the neighbors list, applying a function to assign binary weights, and explicitly assigning these weights in the `nb2listw` function.

We start by assigning a value of 1 to each neighbor using `lapply`:

```{r}
b_weights <- lapply(wm_q, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_q, 
                       glist = b_weights, 
                       style = "B")
b_weights2
```

With the proper weights assigned, compute the lag variable from our weights and GDPPC.

```{r}
lag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
lag.res <- as.data.frame(lag_sum)
colnames(lag.res) <- c("NAME_3", "lag_sum GDPPC")
```

 examine the result:

```{r}
lag_sum
```
::: {.notebox .lightbulb data-latex="lightbulb"}
This method involves summing up the values of neighboring observations to calculate the spatial lag. Unlike the row-standardized method, this doesn't involve any kind of averaging or standardization, so the total influence is simply the sum of the influences from each neighbor. This approach is particularly useful when dealing with binary data (like 0 or 1 values).
*summarized from: [Anselin](https://geodacenter.github.io/workbook/4d_weights_applications/lab4d.html)*
:::

append the *lag_sum GDPPC* field to the *hunan* sf data frame:
```{r}
hunan <- left_join(hunan, lag.res)
```

plot both *GDPPC* and *Spatial Lag Sum GDPPC* for comparison.
```{r fig.width=12, fig.height=8}
gdppc <- qtm(hunan, "GDPPC")
lag_sum_gdppc <- qtm(hunan, "lag_sum GDPPC")
tmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)
```

### Spatial window average

Spatial window average uses row-standardized weights and includes the diagonal element. To achieve this in R, we need to add the diagonal element to the neighbors' structure before assigning weights.

Add the diagonal element using *include.self()* from **spdep**
```{r}
wm_qs <- include.self(wm_q)
```

obtain weights with `nb2listw()`
```{r}
wm_qs <- nb2listw(wm_qs)
wm_qs
```

create the lag variable from our weight structure and GDPPC variable:
```{r}
lag_w_avg_gpdpc <- lag.listw(wm_qs, 
                             hunan$GDPPC)
lag_w_avg_gpdpc
```

convert the lag variable listw object into a data.frame:
```{r}
lag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))
lag_wm_qs.res <- as.data.frame(lag.list.wm_qs)
colnames(lag_wm_qs.res) <- c("NAME_3", "lag_window_avg GDPPC")
```

 append *lag_window_avg GDPPC* values to `hunan`:
```{r}
hunan <- left_join(hunan, lag_wm_qs.res)
```

compare the values of lag GDPPC and Spatial window average by using `kable()`
```{r}
hunan %>%
  select("County", 
         "lag GDPPC", 
         "lag_window_avg GDPPC") %>%
  kable()
```

use `qtm()` to plot the *lag_gdppc* and *w_ave_gdppc* maps next to each other for quick comparison:

```{r fig.width=12, fig.height=8}
w_avg_gdppc <- qtm(hunan, "lag_window_avg GDPPC")
tmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)
```

::: {.notebox .lightbulb data-latex="lightbulb"}
This concept extends the idea of spatial lag by including the observation itself in the average calculation. It's like creating a window that includes the value at a specific location and its neighbors, and then computing the average of all these values. This method is useful when you want to take into account both the value at a specific point and the influence of its surroundings.
*summarized from: [Anselin](https://geodacenter.github.io/workbook/4d_weights_applications/lab4d.html)*
:::


### Spatial window sum

Spatial window sum is similar to window average but without using row-standardized weights.

Let's add the diagonal element to the neighbor list:

```{r}
wm_qs <- include.self(wm_q)
```

Next, we assign binary weights:
```{r}
b_weights <- lapply(wm_qs, function(x) 0*x + 1)
b_weights2 <- nb2listw(wm_qs, glist = b_weights, style = "B")
b_weights2
```

Now, we can compute the lag variable with `lag.listw()`:
```{r}
w_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))
w_sum_gdppc
```

Next, we convert the lag variable listw object into a data.frame:
```{r}
w_sum_gdppc.res <- as.data.frame(w_sum_gdppc)
colnames(w_sum_gdppc.res) <- c("NAME_3", "w_sum GDPPC")
```

Now, we append w_sum GDPPC values to hunan:
```{r}
hunan <- left_join(hunan, w_sum_gdppc.res)
```

use `kable()` To compare the values of lag GDPPC and Spatial window average
```{r}
hunan %>%
  select("County", "lag_sum GDPPC", "w_sum GDPPC") %>%
  kable()
```

Finally, we'll use `qtm()` to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison:
```{r fig.width=12, fig.height=8}
w_sum_gdppc <- qtm(hunan, "w_sum GDPPC")
tmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)
```

::: {.notebox .lightbulb data-latex="lightbulb"}
This is similar to the spatial window average, but instead of averaging the values, it sums them up. This method calculates the total value by adding the value at a specific location to the sum of its neighboring values. It provides a more cumulative measure of spatial influence compared to the average.
*summarized from: [Anselin](https://geodacenter.github.io/workbook/4d_weights_applications/lab4d.html)*
:::


## References
-   [r4gdsa chapter 8](https://r4gdsa.netlify.app/chap08#row-standardised-weights-matrix)
- [Anselin - Weights Applications](https://geodacenter.github.io/workbook/4d_weights_applications/lab4d.html)
- [Anselin - Contiguity Weights](https://lanselin.github.io/introbook_vol1/CHcontiguityweights.html)
- [Getis - Spatial Analysis Handbook](https://learnr.web.unc.edu/wp-content/uploads/sites/7634/2020/03/Getis_2010_HandbookAppSpatAnalysis-1.pdf)